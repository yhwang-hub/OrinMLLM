"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Frequency","Mhz","484.13",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","103,733",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Memory Throughput","%","70.73",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Duration","us","214.24",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.64",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L2 Cache Throughput","%","70.73",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Active Cycles","cycle","82,080.19",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","26.67",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight","","","","SOLBottleneck","OPT","Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.","",""
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The kernel achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Buffer Size","Mbyte","8.39",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Dropped Samples","sample","0",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Sampling Interval","us","1",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","# Pass Groups","","2",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.73",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.70",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issue Slots Busy","%","18.24",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.73",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","SM Busy","%","27.76",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (27.8%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck.","",""
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Busy","%","31.63",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Max Bandwidth","%","70.73",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L1/TEX Hit Rate","%","0.32",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Ratio","","0",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Hit Rate","%","50.15",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Pipes Busy","%","9.89",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","WRN","The optional metric dram__bytes_read.sum.pct_of_peak_sustained_elapsed could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from DRAM might not be optimal. On average, only 31.8 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 99.6% of sectors missed in L2. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","local","0.6716"
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","One or More Eligible","%","18.32",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Issued Warp Per Scheduler","","0.18",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","No Eligible","%","81.68",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Active Warps Per Scheduler","warp","10.67",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.23",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 5.5 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this kernel allocates an average of 10.67 active warps per scheduler, but only an average of 0.23 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","29.27"
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","58.24",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","58.46",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.73",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this kernel spends 52.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 90.8% of the total average of 58.2 cycles between issuing two instructions.","global","29.27"
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","14,912",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Executed Instructions","inst","954,368",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","14,968.41",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Issued Instructions","inst","957,978",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Block Size","","128",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Grid Size","","512",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Registers Per Thread","register/thread","16",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","# SMs","SM","16",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Threads","thread","65,536",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Uses Green Context","","0",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Waves Per SM","","2.67",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit SM","block","16",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Registers","block","32",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Shared Mem","block","16",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Warps","block","12",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Active Warps per SM","warp","48",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Occupancy","%","100",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Occupancy","%","88.83",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Active Warps Per SM","warp","42.64",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (88.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","11.17"
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","82,080.19",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","1,367,024",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","80,895.12",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","830,224",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","82,080.19",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","1,367,024",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","81,718.77",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","5,468,096",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WorkloadDistribution","","","","WorkloadImbalance","WRN","The optional metric dram__cycles_active.avg could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions Ratio","%","0.08",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions","inst","75,776",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Efficiency","%","100",
"0","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Avg. Divergent Branches","","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Frequency","Mhz","601.72",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","81,336",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Memory Throughput","%","65.18",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Duration","us","135.17",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","30.33",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L2 Cache Throughput","%","65.18",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Active Cycles","cycle","60,455",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","13.20",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight","","","","SOLBottleneck","OPT","Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.","",""
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The kernel achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Buffer Size","Mbyte","8.39",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Dropped Samples","sample","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Sampling Interval","us","1",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","# Pass Groups","","2",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.54",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.52",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issue Slots Busy","%","13.59",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.54",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","SM Busy","%","13.59",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","89.1"
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Busy","%","30.35",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Max Bandwidth","%","65.18",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L1/TEX Hit Rate","%","40.05",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Ratio","","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Hit Rate","%","66.83",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Pipes Busy","%","10.28",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","WRN","The optional metric dram__bytes_read.sum.pct_of_peak_sustained_elapsed could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from DRAM might not be optimal. On average, only 31.6 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 99.5% of sectors missed in L2. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","local","1.322"
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global stores to L2 might not be optimal. On average, only 16.0 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 50.1% of sectors missed in L1TEX. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global stores.","global","16.34"
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","One or More Eligible","%","11.62",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Issued Warp Per Scheduler","","0.12",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","No Eligible","%","88.38",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Active Warps Per Scheduler","warp","8.99",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.16",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 8.6 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this kernel allocates an average of 8.99 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections.","local","34.82"
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","77.37",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","77.92",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.50",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this kernel spends 71.4 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 92.3% of the total average of 77.4 cycles between issuing two instructions.","global","34.82"
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","8,160",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Executed Instructions","inst","522,240",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","8,218.20",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Issued Instructions","inst","525,965",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Block Size","","128",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Grid Size","","512",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Registers Per Thread","register/thread","17",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","# SMs","SM","16",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Threads","thread","65,536",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Uses Green Context","","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Waves Per SM","","2.67",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit SM","block","16",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Registers","block","21",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Shared Mem","block","16",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Warps","block","12",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Active Warps per SM","warp","48",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Occupancy","%","100",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Occupancy","%","87.88",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Active Warps Per SM","warp","42.18",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (87.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","12.12"
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","60,455",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","996,080",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","59,205.88",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","650,480",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","60,455",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","996,080",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","70,700.16",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","3,984,320",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WorkloadDistribution","","","","WorkloadImbalance","WRN","The optional metric dram__cycles_active.avg could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions Ratio","%","0.09",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions","inst","45,056",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Efficiency","%","100",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Avg. Divergent Branches","","0",
"1","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SourceCounters","","","","UncoalescedGlobalAccess","OPT","This kernel has uncoalesced global accesses resulting in a total of 262144 excessive sectors (40% of the total 657408 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.","global","29.04"
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Frequency","Mhz","608.74",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","65,258",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Memory Throughput","%","56.32",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Duration","us","107.20",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.92",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L2 Cache Throughput","%","56.32",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Active Cycles","cycle","43,943.69",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.60",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight","","","","SOLBottleneck","OPT","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.","",""
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The kernel achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Buffer Size","Mbyte","1.05",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Dropped Samples","sample","0",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Sampling Interval","us","1",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","# Pass Groups","","2",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.43",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issue Slots Busy","%","10.77",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.43",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","SM Busy","%","11.21",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","93.45"
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Busy","%","25.20",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Max Bandwidth","%","56.32",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L1/TEX Hit Rate","%","0.65",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Ratio","","0",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Hit Rate","%","50.21",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Pipes Busy","%","9.36",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","WRN","The optional metric dram__bytes_read.sum.pct_of_peak_sustained_elapsed could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from DRAM might not be optimal. On average, only 31.6 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 99.5% of sectors missed in L2. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","local","1.322"
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","One or More Eligible","%","10.83",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Issued Warp Per Scheduler","","0.11",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","No Eligible","%","89.17",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Active Warps Per Scheduler","warp","10.47",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.16",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 9.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this kernel allocates an average of 10.47 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","43.68"
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","96.68",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","97.92",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.12",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this kernel spends 88.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 91.2% of the total average of 96.7 cycles between issuing two instructions.","global","43.68"
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","4,672",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Executed Instructions","inst","299,008",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","4,731.94",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Issued Instructions","inst","302,844",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Block Size","","128",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Grid Size","","512",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Registers Per Thread","register/thread","16",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","# SMs","SM","16",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Threads","thread","65,536",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Uses Green Context","","0",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Waves Per SM","","2.67",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit SM","block","16",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Registers","block","32",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Shared Mem","block","16",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Warps","block","12",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Active Warps per SM","warp","48",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Occupancy","%","100",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Occupancy","%","86.81",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Active Warps Per SM","warp","41.67",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (86.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","13.19"
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","43,943.69",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","743,816",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","42,825.62",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","522,000",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","43,943.69",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","743,816",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","43,692.16",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","2,975,264",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","WorkloadDistribution","","","","WorkloadImbalance","WRN","The optional metric dram__cycles_active.avg could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions Ratio","%","0.15",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions","inst","45,056",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Efficiency","%","100",
"2","3650068","bench_emb","127.0.0.1","original::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(128, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Avg. Divergent Branches","","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Frequency","Mhz","603.74",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","90,150",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Memory Throughput","%","77.56",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Duration","us","149.31",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.18",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L2 Cache Throughput","%","77.56",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Active Cycles","cycle","76,983.56",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","5.07",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight","","","","SOLBottleneck","OPT","Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.","",""
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The kernel achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Buffer Size","Mbyte","1.05",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Dropped Samples","sample","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Sampling Interval","us","1",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","# Pass Groups","","2",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.19",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.18",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issue Slots Busy","%","4.75",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.19",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","SM Busy","%","4.75",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","97.17"
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Busy","%","36.40",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Max Bandwidth","%","77.56",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L1/TEX Hit Rate","%","0.70",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Ratio","","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Hit Rate","%","50.17",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Pipes Busy","%","5.07",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","WRN","The optional metric dram__bytes_read.sum.pct_of_peak_sustained_elapsed could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from DRAM might not be optimal. On average, only 31.6 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 99.6% of sectors missed in L2. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","local","1.323"
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","One or More Eligible","%","4.76",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Issued Warp Per Scheduler","","0.05",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","No Eligible","%","95.24",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Active Warps Per Scheduler","warp","13.07",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.08",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 21.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this kernel allocates an average of 13.07 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","22.44"
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","274.60",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","279.94",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.71",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this kernel spends 211.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 77.1% of the total average of 274.6 cycles between issuing two instructions.","global","22.44"
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","3,584",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Executed Instructions","inst","229,376",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","3,653.69",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Issued Instructions","inst","233,836",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Block Size","","256",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Grid Size","","512",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Registers Per Thread","register/thread","18",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Shared Memory Configuration Size","Kbyte","8.19",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","# SMs","SM","16",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Threads","thread","131,072",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Uses Green Context","","0",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Waves Per SM","","5.33",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit SM","block","16",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Registers","block","10",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Shared Mem","block","8",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Warps","block","6",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Active Warps per SM","warp","48",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Occupancy","%","100",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Occupancy","%","90.83",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Active Warps Per SM","warp","43.60",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","76,983.56",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","1,291,368",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","76,963.25",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","721,384",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","76,983.56",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","1,291,368",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","76,781.06",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","5,165,472",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WorkloadDistribution","","","","WorkloadImbalance","WRN","The optional metric dram__cycles_active.avg could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions Ratio","%","0.18",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions","inst","40,960",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Efficiency","%","100",
"3","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp32(int, int, int, const int *, const float *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Avg. Divergent Branches","","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Frequency","Mhz","606.17",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","96,758",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Memory Throughput","%","75.62",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Duration","us","159.62",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","36.98",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L2 Cache Throughput","%","75.62",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Active Cycles","cycle","77,158.12",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","5.86",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight","","","","SOLBottleneck","OPT","Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.","",""
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The kernel achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Buffer Size","Mbyte","2.10",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Dropped Samples","sample","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Sampling Interval","us","1",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","# Pass Groups","","2",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.21",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.20",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issue Slots Busy","%","5.32",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.21",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","SM Busy","%","6.14",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","96.93"
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Busy","%","37.46",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Max Bandwidth","%","75.62",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L1/TEX Hit Rate","%","34.56",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Ratio","","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Hit Rate","%","62.07",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Pipes Busy","%","5.12",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","WRN","The optional metric dram__bytes_read.sum.pct_of_peak_sustained_elapsed could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from DRAM might not be optimal. On average, only 31.2 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 99.4% of sectors missed in L2. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","local","2.565"
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global stores to L2 might not be optimal. On average, only 16.0 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 57.6% of sectors missed in L1TEX. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global stores.","global","21.76"
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","One or More Eligible","%","5.45",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Issued Warp Per Scheduler","","0.05",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","No Eligible","%","94.55",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Active Warps Per Scheduler","warp","10.22",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.10",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 18.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this kernel allocates an average of 10.22 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","24.38"
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","187.46",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","190.73",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.97",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this kernel spends 121.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 64.9% of the total average of 187.5 cycles between issuing two instructions.","global","24.38"
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","4,032",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Executed Instructions","inst","258,048",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","4,102.38",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Issued Instructions","inst","262,552",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Block Size","","256",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Grid Size","","512",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Registers Per Thread","register/thread","24",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Shared Memory Configuration Size","Kbyte","8.19",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","# SMs","SM","16",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Threads","thread","131,072",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Uses Green Context","","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Waves Per SM","","5.33",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit SM","block","16",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Registers","block","10",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Shared Mem","block","8",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Warps","block","6",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Active Warps per SM","warp","48",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Occupancy","%","100",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Occupancy","%","83.01",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Active Warps Per SM","warp","39.84",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (83.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","16.99"
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","77,158.12",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","1,292,712",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","74,605",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","773,984",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","77,158.12",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","1,292,712",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","75,253.81",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","5,170,848",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WorkloadDistribution","","","","WorkloadImbalance","WRN","The optional metric dram__cycles_active.avg could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions Ratio","%","0.13",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions","inst","32,768",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Efficiency","%","100",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Avg. Divergent Branches","","0",
"4","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_fp16(int, int, int, const int *, const __half *, float *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SourceCounters","","","","UncoalescedGlobalAccess","OPT","This kernel has uncoalesced global accesses resulting in a total of 262144 excessive sectors (40% of the total 659456 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) has additional information on reducing uncoalesced device memory accesses.","global","30.65"
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Frequency","Mhz","611.25",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","51,443",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Memory Throughput","%","67.93",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Duration","us","84.16",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.37",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","L2 Cache Throughput","%","67.93",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","SM Active Cycles","cycle","39,678.31",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","7.58",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight","","","","SOLBottleneck","OPT","Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the L2 bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or whether there are values you can (re)compute.","",""
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 64:1. The kernel achieved 0% of this device's fp32 peak performance and 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Buffer Size","Mbyte","4.19",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Dropped Samples","sample","0",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","Maximum Sampling Interval","us","1",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","PM Sampling","# Pass Groups","","2",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Active","inst/cycle","0.32",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issue Slots Busy","%","8.06",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","Issued Ipc Active","inst/cycle","0.32",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Compute Workload Analysis","SM Busy","%","8.06",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","ComputeWorkloadAnalysis","","","","HighPipeUtilization","OPT","All compute pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.","local","94.19"
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Busy","%","31.96",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Max Bandwidth","%","67.93",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L1/TEX Hit Rate","%","1.38",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Compression Ratio","","0",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","L2 Hit Rate","%","50.23",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Memory Workload Analysis","Mem Pipes Busy","%","4.85",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Chart","","","","MemoryL2Compression","WRN","The optional metric dram__bytes_read.sum.pct_of_peak_sustained_elapsed could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","OPT","The memory access pattern for global loads from DRAM might not be optimal. On average, only 31.2 of the 32 bytes transmitted per sector are utilized by each thread. This applies to the 99.4% of sectors missed in L2. This could possibly be caused by a stride between threads. Check the Source Counters section for uncoalesced global loads.","local","2.565"
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","One or More Eligible","%","8.10",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Issued Warp Per Scheduler","","0.08",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","No Eligible","%","91.90",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Active Warps Per Scheduler","warp","11.46",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.17",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","SchedulerStats","","","","IssueSlotUtilization","OPT","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 12.4 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 12 warps per scheduler, this kernel allocates an average of 11.46 active warps per scheduler, but only an average of 0.17 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, avoid possible load imbalances due to highly different execution durations per warp. Reducing stalls indicated on the Warp State Statistics and Source Counters sections can help, too.","local","32.07"
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","141.55",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","144.36",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Active Threads Per Warp","","32",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.39",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","OPT","On average, each warp of this kernel spends 115.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory. This stall type represents about 81.3% of the total average of 141.5 cycles between issuing two instructions.","global","32.07"
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Samples) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason.","",""
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","3,136",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Executed Instructions","inst","200,704",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","3,198.23",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Instruction Statistics","Issued Instructions","inst","204,687",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Block Size","","256",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Function Cache Configuration","","CachePreferNone",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Grid Size","","512",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Registers Per Thread","register/thread","18",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Shared Memory Configuration Size","Kbyte","8.19",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","# SMs","SM","16",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Threads","thread","131,072",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Uses Green Context","","0",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Launch Statistics","Waves Per SM","","5.33",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit SM","block","16",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Registers","block","10",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Shared Mem","block","8",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Block Limit Warps","block","6",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Active Warps per SM","warp","48",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Theoretical Occupancy","%","100",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Occupancy","%","87.07",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","Achieved Active Warps Per SM","warp","41.79",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Occupancy","","","","AchievedOccupancy","OPT","The difference between calculated theoretical (100.0%) and measured achieved occupancy (87.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy.","global","12.93"
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L1 Active Cycles","cycle","39,678.31",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L1 Elapsed Cycles","cycle","675,032",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average L2 Active Cycles","cycle","38,618.75",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total L2 Elapsed Cycles","cycle","411,560",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SM Active Cycles","cycle","39,678.31",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SM Elapsed Cycles","cycle","675,032",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Average SMSP Active Cycles","cycle","39,505.97",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","GPU and Memory Workload Distribution","Total SMSP Elapsed Cycles","cycle","2,700,128",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","WorkloadDistribution","","","","WorkloadImbalance","WRN","The optional metric dram__cycles_active.avg could not be found. Collecting it as an additional metric could enable the rule to provide more guidance.","",""
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions Ratio","%","0.16",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Instructions","inst","32,768",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Branch Efficiency","%","100",
"5","3650068","bench_emb","127.0.0.1","optimized::emb_kernel_cu_pure_fp16_impl(int, int, int, const int *, const __half *, __half *)","1","7","(256, 1, 1)","(512, 1, 1)","0","8.7","Source Counters","Avg. Divergent Branches","","0",
